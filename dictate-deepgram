#!/usr/bin/env python3
"""
Voice dictation using Deepgram live transcription API.

Usage: dictate-deepgram [--lang=LANG]
  --lang=LANG          Language code. Examples:
                         en-US        English (default)
                         de           German
                         es           Spanish
                         auto         Auto-detect language

Toggle behavior: Run once to start, run again to stop.
Press Ctrl+C to stop manually.

Requires:
  - pip install deepgram-sdk pyaudio
  - DEEPGRAM_API_KEY environment variable set
"""

import argparse
import os
import signal
import subprocess
import sys
import threading
import queue
import time
from pathlib import Path

# PID file for toggle behavior
PIDFILE = Path("/tmp/dictate-deepgram.pid")

# Global stop event for signal handling
_global_stop_event = None


def notify(message: str, timeout_ms: int = 2000, urgency: str = "normal"):
    """Show desktop notification."""
    try:
        subprocess.run(
            ["notify-send", "-t", str(timeout_ms), "-u", urgency,
             "-h", "string:x-canonical-private-synchronous:dictation",
             "-i", "audio-input-microphone", "Dictation", message],
            check=False,
            capture_output=True
        )
    except FileNotFoundError:
        pass


def xdotool_type(text: str):
    """Type text using xdotool. Fast, atomic operation."""
    if text:
        subprocess.run(
            ["xdotool", "type", "--clearmodifiers", "--delay", "0", "--", text],
            check=False
        )


def xdotool_backspace(count: int):
    """Send backspace keys using xdotool. Single atomic operation."""
    if count > 0:
        subprocess.run(
            ["xdotool", "key", "--clearmodifiers", "--delay", "0"] + ["BackSpace"] * count,
            check=False
        )


def check_stop_requested() -> bool:
    """Check if another instance requested us to stop."""
    return not PIDFILE.exists()


def request_stop():
    """Request running instance to stop by removing PID file."""
    if PIDFILE.exists():
        try:
            pid = int(PIDFILE.read_text().strip())
        except (ValueError, FileNotFoundError):
            return False
        PIDFILE.unlink(missing_ok=True)
        # Give it a moment to notice the PID file removal
        time.sleep(0.2)
        # If still running, send SIGTERM and wait for it to die
        try:
            os.kill(pid, 0)  # Check if alive
            os.kill(pid, signal.SIGTERM)
            # Wait for process to actually terminate (up to 1 second)
            for _ in range(10):
                time.sleep(0.1)
                try:
                    os.kill(pid, 0)
                except ProcessLookupError:
                    break  # Process is dead
        except ProcessLookupError:
            pass
        return True
    return False


def acquire_lock() -> bool:
    """Try to acquire the lock. Returns False if another instance is running."""
    if PIDFILE.exists():
        # Check if the process is actually running
        try:
            pid = int(PIDFILE.read_text().strip())
            os.kill(pid, 0)  # Check if alive (doesn't actually kill)
            # Process is running - request it to stop
            request_stop()
            return False
        except (ProcessLookupError, ValueError):
            # Process is dead, stale PID file - clean it up
            PIDFILE.unlink(missing_ok=True)

    PIDFILE.write_text(str(os.getpid()))
    return True


def release_lock():
    """Release the lock."""
    PIDFILE.unlink(missing_ok=True)


class DisplayState:
    """
    Track what's currently typed on screen using actual text content.

    Stores the full text on screen and diffs against it on each update,
    so interim hypothesis revisions (same length but different content,
    shorter replacements, changed prefixes) are all handled correctly.
    """

    def __init__(self):
        self.final_len = 0      # Characters that are permanent (never backspace past)
        self.screen_text = ""   # Actual text currently on screen
        self.lock = threading.Lock()

    def update(self, new_text: str, is_final: bool):
        """
        Update the display to show new_text.

        Finds the first point of divergence (after final_len) between
        the current screen text and the new text, backspaces to that
        point, and retypes the new suffix.
        """
        with self.lock:
            old = self.screen_text

            # Find first divergence point (never before final_len)
            diverge = self.final_len
            limit = min(len(old), len(new_text))
            while diverge < limit and old[diverge] == new_text[diverge]:
                diverge += 1

            # Backspace from end of old text to divergence point
            bs_count = len(old) - diverge
            if bs_count > 0:
                xdotool_backspace(bs_count)

            # Type new text from divergence point onward
            suffix = new_text[diverge:]
            if suffix:
                xdotool_type(suffix)

            self.screen_text = new_text

            if is_final:
                self.final_len = len(new_text)
                # Add space separator after finalized phrase
                xdotool_type(" ")
                self.screen_text += " "
                self.final_len += 1


class MicrophoneStream:
    """Opens a recording stream as a generator yielding audio chunks."""

    def __init__(self, rate: int = 16000, chunk_size: int = 1600):
        self._rate = rate
        self._chunk_size = chunk_size
        self._buff = queue.Queue()
        self._closed = True
        self._audio_interface = None
        self._audio_stream = None

    def __enter__(self):
        import pyaudio

        self._audio_interface = pyaudio.PyAudio()
        self._audio_stream = self._audio_interface.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self._rate,
            input=True,
            frames_per_buffer=self._chunk_size,
            stream_callback=self._fill_buffer,
        )
        self._closed = False
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()

    def close(self):
        if not self._closed:
            self._closed = True
            self._buff.put(None)
            if self._audio_stream:
                self._audio_stream.stop_stream()
                self._audio_stream.close()
            if self._audio_interface:
                self._audio_interface.terminate()

    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):
        import pyaudio
        self._buff.put(in_data)
        return None, pyaudio.paContinue

    def generator(self):
        while not self._closed:
            chunk = self._buff.get()
            if chunk is None:
                return
            data = [chunk]

            # Grab any additional available chunks
            while True:
                try:
                    chunk = self._buff.get(block=False)
                    if chunk is None:
                        return
                    data.append(chunk)
                except queue.Empty:
                    break

            yield b"".join(data)


def get_deepgram_api_key() -> str:
    """Get Deepgram API key from env var or config file."""
    api_key = os.environ.get("DEEPGRAM_API_KEY")
    if api_key:
        return api_key

    # Try config file
    config_path = Path.home() / ".config/deepgram-api-key"
    if config_path.exists():
        return config_path.read_text().strip()

    return None


def run_streaming_recognition(lang: str):
    """Run streaming speech recognition with real-time display."""
    import json
    from urllib.parse import urlencode
    import websockets.sync.client as websockets_sync_client

    api_key = get_deepgram_api_key()
    if not api_key:
        notify("Error: No API key found")
        print("Set DEEPGRAM_API_KEY or place key at ~/.config/deepgram-api-key")
        sys.exit(1)

    # Handle language specification
    # For streaming, "multi" enables multilingual code-switching
    if lang == "auto":
        language = "multi"
    else:
        language = lang

    global _global_stop_event

    # State tracking
    display = DisplayState()
    stop_event = threading.Event()
    _global_stop_event = stop_event  # Allow signal handler to trigger stop
    mic_stream = None
    last_activity = time.time()
    activity_lock = threading.Lock()
    SILENCE_TIMEOUT = 7
    stopped_by_silence = False

    # Track the current accumulated text
    final_text = ""
    final_text_lock = threading.Lock()

    def update_activity():
        nonlocal last_activity
        with activity_lock:
            last_activity = time.time()

    def check_stop():
        nonlocal mic_stream, stopped_by_silence
        while not stop_event.is_set():
            if check_stop_requested():
                stop_event.set()
                if mic_stream:
                    mic_stream.close()
                return

            with activity_lock:
                silence_duration = time.time() - last_activity

            if silence_duration >= SILENCE_TIMEOUT:
                stopped_by_silence = True
                stop_event.set()
                if mic_stream:
                    mic_stream.close()
                return

            time.sleep(0.1)

    stop_thread = threading.Thread(target=check_stop, daemon=True)
    stop_thread.start()

    # Build connection parameters
    # Note: keyterm requires repeated params for multiple terms (Nova-3 feature)
    # SDK only supports single keyterm, so we build URL manually
    params = [
        ("model", "nova-3"),
        ("language", language),
        ("punctuate", "true"),
        ("interim_results", "true"),  # Keeps activity timer alive during continuous speech
        ("encoding", "linear16"),
        ("sample_rate", "16000"),
        ("channels", "1"),
        ("smart_format", "true"),
        ("endpointing", "500"),       # Faster finalization, less interim churn
        ("dictation", "true"),        # Spoken "comma"/"period" become punctuation
        ("utterance_end_ms", "2000"), # Cleaner end-of-utterance detection
        ("vad_events", "true"),       # Reset silence timer on voice activity
        ("no_delay", "true"),         # Lower latency for interim results
    ]

    # Add keyterms - each as separate param for individual boosting
    keyterms = ["appwrite", "claude", "claude code", "docs", "mcp", "liviano", "bikecheck", "tmux", "dev server"]
    for term in keyterms:
        params.append(("keyterm", term))

    ws_url = "wss://api.deepgram.com/v1/listen?" + urlencode(params)
    headers = {"Authorization": f"Token {api_key}"}

    try:
        with MicrophoneStream() as stream:
            mic_stream = stream

            with websockets_sync_client.connect(ws_url, additional_headers=headers) as ws:
                # Thread to send audio
                def send_audio():
                    for chunk in stream.generator():
                        if stop_event.is_set():
                            break
                        try:
                            ws.send(chunk)
                        except Exception:
                            break

                audio_thread = threading.Thread(target=send_audio, daemon=True)
                audio_thread.start()

                # Receive transcripts in main thread
                for msg in ws:
                    if stop_event.is_set():
                        break

                    try:
                        result = json.loads(msg)
                    except (json.JSONDecodeError, TypeError):
                        continue

                    # Handle VAD and utterance events (reset silence timer)
                    msg_type = result.get("type")
                    if msg_type in ("SpeechStarted", "UtteranceEnd"):
                        update_activity()
                        continue

                    # Skip non-transcript messages
                    if msg_type != "Results":
                        continue

                    try:
                        transcript = result["channel"]["alternatives"][0]["transcript"]
                    except (KeyError, IndexError):
                        continue

                    if not transcript:
                        continue

                    update_activity()
                    is_final = result.get("is_final", False)

                    with final_text_lock:
                        if is_final:
                            full_text = final_text + transcript
                            display.update(full_text, is_final=True)
                            final_text = full_text + " "
                        else:
                            full_text = final_text + transcript
                            display.update(full_text, is_final=False)

    except Exception as e:
        err_str = str(e)
        if stop_event.is_set():
            pass
        elif "cancelled" in err_str.lower():
            pass
        else:
            notify(f"Error: {e}")
            raise
    finally:
        stop_event.set()
        if mic_stream:
            mic_stream.close()

    with final_text_lock:
        return final_text.strip(), stopped_by_silence


def main():
    parser = argparse.ArgumentParser(description="Deepgram STT dictation")
    parser.add_argument("--lang", default="en-US", help="Language code (en-US, de, es, auto)")
    args = parser.parse_args()

    # Check credentials early
    if not get_deepgram_api_key():
        notify("Error: No API key found")
        print("Set DEEPGRAM_API_KEY or place key at ~/.config/deepgram-api-key")
        sys.exit(1)

    # Toggle behavior
    if not acquire_lock():
        sys.exit(0)

    # Handle signals for clean shutdown
    def signal_handler(signum, frame):
        if _global_stop_event:
            _global_stop_event.set()
        release_lock()
        sys.exit(0)

    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)

    try:
        run_streaming_recognition(args.lang)
    except KeyboardInterrupt:
        pass
    except Exception as e:
        notify(f"Error: {e}")
        raise
    finally:
        release_lock()


if __name__ == "__main__":
    main()
